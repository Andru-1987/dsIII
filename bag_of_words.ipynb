{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /home/codespace/.local/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4) (2.6)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# URLs de los medios\n",
    "urls = {\n",
    "    \"La Naci칩n\": \"https://www.lanacion.com.ar/\",\n",
    "    \"Clarin\": \"https://www.clarin.com/\",\n",
    "    \"Infobae\": \"https://www.infobae.com/\"\n",
    "}\n",
    "\n",
    "# Lista para almacenar los titulares\n",
    "data = []\n",
    "\n",
    "for medio, url in urls.items():\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    titles = soup.find_all(\"h2\")[:10]\n",
    "    \n",
    "    for title in titles:\n",
    "        data.append([medio, title.get_text(strip=True)])\n",
    "\n",
    "# Crear un DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"diario\", \"titular\"])\n",
    "\n",
    "storage_csv = \"./headlines/titulares.csv\"\n",
    "df.to_csv(storage_csv, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW Simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Top 10 palabras m치s usadas:**\n",
      "de: 37\n",
      "la: 25\n",
      "el: 21\n",
      "en: 15\n",
      "y: 14\n",
      "a: 13\n",
      "que: 13\n",
      "del: 10\n",
      "una: 9\n",
      "los: 6\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(storage_csv)\n",
    "\n",
    "#  limpieza de cada texto o titular de cada diario\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text) \n",
    "    words = text.split()\n",
    "    return words\n",
    "\n",
    "# Aplicar la funci칩n a todos los titulares\n",
    "all_words = []\n",
    "for title in df[\"titular\"]:\n",
    "    all_words.extend(tokenize(title))\n",
    "\n",
    "# Contar la frecuencia de las palabras\n",
    "word_freq = Counter(all_words)\n",
    "\n",
    "# Obtener las 10 palabras m치s comunes\n",
    "top_10_words = word_freq.most_common(10)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"**Top 10 palabras m치s usadas:**\")\n",
    "for word, freq in top_10_words:\n",
    "    print(f\"{word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Cargar el CSV\n",
    "df = pd.read_csv(\"titulares_noticias.csv\")\n",
    "\n",
    "# Funci칩n para limpiar y tokenizar titulares\n",
    "def tokenize(text):\n",
    "    text = text.lower()  # Convertir a min칰sculas\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Eliminar signos de puntuaci칩n\n",
    "    words = text.split()  # Tokenizar en palabras\n",
    "    return words\n",
    "\n",
    "# Aplicar la funci칩n a todos los titulares\n",
    "all_words = []\n",
    "for title in df[\"Titular\"]:\n",
    "    all_words.extend(tokenize(title))\n",
    "\n",
    "# Contar la frecuencia de las palabras\n",
    "word_freq = Counter(all_words)\n",
    "\n",
    "# Obtener las 10 palabras m치s comunes\n",
    "top_10_words = word_freq.most_common(10)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"游댳 **Top 10 palabras m치s usadas:**\")\n",
    "for word, freq in top_10_words:\n",
    "    print(f\"{word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
